---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2'
geometry: margin=1in
output:
  pdf_document:
    latex_engine: xelatex
  number_sections: yes
  html_document: default
  toc: yes
fontsize: 11pt
---

## Instructions (Please Read Carefully):

* $\textbf{Due Date: Sunday March 15 2020, 11:59pm}$

* No page limit, but be reasonable

* Do not modify fontsize, margin or line-spacing settings

* One student from each group should submit the lab to their student github repository by the deadline; submission and revisions made after the deadline will not be graded

* Answers should clearly explain your reasoning; do not simply 'output dump' the results of code without explanation 

* Submit two files:
    
    1. A pdf file that details your answers. Include all R code used to produce the answers. Do not suppress the codes in your pdf file
    
    2. The R markdown (Rmd) file used to produce the pdf file
  
    The assignment will not be graded unless **both** files are submitted
      
* Name your files to include all group members names. For example the students' names are Stan Cartman and Kenny Kyle, name your files as follows:

    * `StanCartman_KennyKyle_Lab2.Rmd`
    * `StanCartman_KennyKyle_Lab2.pdf`
            
* Although it sounds obvious, please write your name on page 1 of your pdf and Rmd files

* All answers should include a detailed narrative; make sure that your audience can easily follow the logic of your analysis. All steps used in modelling must be clearly shown and explained

* If you use libraries and functions for statistical modeling that we have not covered in this course, you must provide an explanation of why such libraries and functions are used and reference the library documentation

* For mathematical formulae, type them in your R markdown file. Do not e.g. write them on a piece of paper, snap a photo, and use the image file

* Incorrectly following submission instructions results in deduction of grades

* Students are expected to act with regard to UC Berkeley Academic Integrity.

\newpage

# The Keeling Curve

In the 1950s, the geochemist Charles David Keeling observed a seasonal pattern in the amount of carbon dioxide present in air samples collected over the course of several years. He was able to attribute this pattern to the difference in the amount of land area and vegetation cover between the northern and southern hemipsheres, and the resulting variation in global rates of photosynthesis as the hemispheres' seasons alternated throughout the year. 

In 1958 Keeling began continuous monitoring of atmospheric carbon dioxide concentrations from the Mauna Loa Observatory in Hawaii and soon observed a trend increase carbon dioxide levels in addition to the seasonal cycle. He was able to attribute this trend increase to growth in global rates of fossil fuel combustion. This trend has continued to the present.

The `co2` data set in R's `datasets` package (automatically loaded with base R) is a monthly time series of atmospheric carbon dioxide concentrations measured in ppm (parts per million) at the Mauna Loa Observatory from 1959 to 1997. The curve graphed by this data is known as the 'Keeling Curve'.

```{r}
plot(co2, col = 'blue', las = 1)
title(main = "Monthly Mean CO2 Variation")
```

\newpage

**Part 1 (4 points)**

Conduct a comprehensive Exploratory Data Analysis on the `co2` series. This should include thorough analyses of the trend, seasonal and irregular elements. Trends both in levels and growth rates should be discussed.

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#EDA
rm(co2)
class(co2)

#Summarize co2 values and see frequency of datapoints
str(co2)
summary(co2)
frequency(co2)
cycle(co2)

#Check for missing values
sum(is.na(co2))

#Histogram
hist(co2)

#Decompose plots
plot(decompose(co2))

#Glimpse into seasonal trend
plot(ts(co2[1:12]), ylab = "First 12 Observations")
plot(ts(co2[13:24]),)

#Boxplot of monthly data
boxplot(co2~cycle(co2), xlab = "Month", ylab = "co2", main = "Monthly co2 levels from 1959 to 1998")

#Correlogram
acf(co2, lag = 100)
pacf(co2, lag.max = 100)

library(fpp2)
ggseasonplot(co2, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("co2") +
  ggtitle("Seasonal plot: co2 levels")

co2 %>% diff() %>% ggtsdisplay(main="")

co2 %>% diff(differences = 2) %>% ggtsdisplay(main="")

co2 %>% diff(differences = 3) %>% ggtsdisplay(main="")



```
The co2 dataset is comprised of 468 observations of data from 1959 to 1998 where each datapoint is one month's data. The co2 levels in the dataset range from between 313.2 to 366.8. The histogram shows us that the most common co2 levels are between 320 and 325, and generally the frequency of co2 values decreases as co2 goes up. There is a small spike of frequencies between co2 level 355 and 360. There are no missing values in the dataset. 

In the decompose plots, we see that the trend appears to be additive, and there is a clear and consistent season trend. Additionally, the variance in the random series seems to be consistent over the time series. 

The seasonality in the data shows that every October, co2 levels are lowest, and in May, co2 levels are highest. The seasonal trend every year precisely follows the same pattern. The time series is not stationary, and when we take the difference, we stil see autocorrelation in the differenced series. 
**Part 2 (3 points)**

Fit a linear time trend model to the `co2` series, and examine the characteristics of the residuals. Compare this to a quadratic time trend model. Discuss whether a logarithmic transformation of the data would be appropriate. Fit a suitable polynomial time trend model that incorporates seasonal dummy variables, and use this model to generate forecasts to the year 2020. 


To create a linear time trend, first we change the data structure that so that we can add a column called 'time index' that starts at 1 increases by 1 for every sequential row in order of time. Then, we fit the linear model where y is equal to the co2 value:

$$y = \beta_0 + \beta_1time$$


```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Convert to tsibble and create time index
library(tsibble)
library(dplyr)
co2 <- as_tsibble(co2) %>% mutate(time_index = row_number())

#Create linear model
linear.trend.fit = lm(value ~ time_index, data=co2)
summary(linear.trend.fit)

#Create dataframe of actual values, fitted values, and residuals
co2.df = data.frame(time=co2$time_index, 
                    co2 = co2$value,
                       fitted.values=linear.trend.fit$fitted.values,
                       residuals = linear.trend.fit$residuals)

#Plot actuals with fitted values
ggplot(data = co2.df, aes(x=time, y=value, colour=variable)) +
  xlab('Month Number Starting from 1959') +
  ylab('co2') +
  geom_line(aes(y=co2 , col='co2 actuals')) +
  geom_line(aes(y=fitted.values, col='Linear Trend Fit')) +
  ggtitle("co2 Actuals with Linear Trend Fit ") +
  ylim(200,700) +
  scale_y_continuous(labels = function(x) format(x/1000, scientific = FALSE)) + 
  theme(title = element_text(size = rel(1)),
        axis.text.y = element_text(angle = 45, hjust = 1)
        )	

library(car)
#Create model diagnostic function
model_diagnostic = function(model) {
  plot(model)
  
  residualPlots(model)  
}

#Linear Model diagnostics
model_diagnostic(linear.trend.fit)

```
The fitted linear model is:
$$y = 311.5 + 0.109time$$
With a p-value of close to 0, the time variable is very significant in explaining co2 levels. 

The quadratic model, where y is equal to the co2 value, is modeled as:
$$y = \beta_0 + \beta_1time + \beta_2time^2$$

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Create quadratic model
quad.trend.fit = lm(value ~ time_index + I(time_index^2), data=co2)
summary(quad.trend.fit)

#Create dataframe of actual values, fitted values, and residuals
co2.df.quad = data.frame(time=co2$time_index, 
                    co2 = co2$value,
                       fitted.values=quad.trend.fit$fitted.values,
                       residuals = quad.trend.fit$residuals)

#Plot actuals with fitted values
ggplot(data = co2.df.quad, aes(x=time, y=value, colour=variable)) +
  xlab('Month Number Starting from 1959') +
  ylab('co2') +
  geom_line(aes(y=co2 , col='co2 actuals')) +
  geom_line(aes(y=fitted.values, col='Quadratic Trend Fit')) +
  ggtitle("co2 Actuals with Quadratic Trend Fit ") +
  ylim(200,700) +
  scale_y_continuous(labels = function(x) format(x/1000, scientific = FALSE)) + 
  theme(title = element_text(size = rel(1)),
        axis.text.y = element_text(angle = 45, hjust = 1)
        )	

#Create model diagnostic function
model_diagnostic = function(model) {
  plot(model)
  
  residualPlots(model)  
}

#Linear Model diagnostics
model_diagnostic(quad.trend.fit)

```
The fitted quadratic model is as follows, where again, the time variable, including the quadratic term, is extrememly significant in predicting co2 level with p-values close to 0:
$$y = 314.8 + + 0.067time + 0.00009time^2$$
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#Create column for seasonal 
library(lubridate)
co2 <- as_tsibble(co2) %>% mutate(month = as.factor(month(index)))

quad.trend.fit2 = lm(value ~ time_index + I(time_index^2) + month, data=co2)
summary(quad.trend.fit2)

#Create dataframe of actual values, fitted values, and residuals
co2.df.quad2 = data.frame(time=co2$time_index, 
                    co2 = co2$value,
                       fitted.values=quad.trend.fit2$fitted.values,
                       residuals = quad.trend.fit2$residuals)

#Plot actuals with fitted values
ggplot(data = co2.df.quad2, aes(x=time, y=value, colour=variable)) +
  xlab('Month Number Starting from 1959') +
  ylab('co2') +
  geom_line(aes(y=co2 , col='co2 actuals')) +
  geom_line(aes(y=fitted.values, col='Quadratic Trend Fit')) +
  ggtitle("co2 Actuals with Quadratic Trend Fit ") +
  ylim(200,700) +
  scale_y_continuous(labels = function(x) format(x/1000, scientific = FALSE)) + 
  theme(title = element_text(size = rel(1)),
        axis.text.y = element_text(angle = 45, hjust = 1)
        )	

#Model diagnostics
model_diagnostic(quad.trend.fit2)

library(forecast)
fc_co2 <- forecast(quad.trend.fit2)
fc_beer %>%
  autoplot(recent_production) +
  ggtitle("Forecasts of beer production using regression") +
  xlab("Year") + ylab("megalitres")




```


**Part 3 (3 points)**

Following all appropriate steps, choose an ARIMA model to fit to the series. Discuss the characteristics of your model and how you selected between alternative ARIMA specifications. Write your model (or models) using backshift notation. Use your model (or models) to generate forecasts to the year 2020. 

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
get.best.arima <- function(x.ts, maxord = c(1,1,1,1,1,1))
{
  best.aic <-1000000
  n <- length(x.ts)
  for (p in 0:maxord[1]) for(d in 0:maxord[2]) for(q in 0:maxord[3])
      for (P in 0:maxord[4]) for(D in 0:maxord[5]) for(Q in 0:maxord[6])
      {
        fit <- Arima(x.ts, order = c(p,d,q),
                     seas = list(order = c(P,D,Q),
                                 frequency(x.ts)), method = "CSS")
        fit.aic <- -2*fit$loglik + 2*(length(fit$coef))
        if (fit.aic < best.aic)
        {
          best.aic <- fit.aic
          best.fit <- fit
          best.model <- c(p,d,q,P,D,Q)
        }
      }
    list(best.aic, best.fit, best.model)
}

best.arima <- get.best.arima(co2, maxord = c(2,2,2,2,2,2))
best.arima

library("forecast")
futurVal <- forecast(best.arima,h=10, level=c(99.5))

co2 %>%
  Arima(order=c(1,1,1), seasonal=c(2,0,2), method = "CSS", lambda=0) %>%
  forecast(h = 264) %>%
  autoplot() +
    ylab("co2") + xlab("Year") + ggtitle("co2 Forecasts for ARIMA(1,1,1)(2,0,2)[12]")

head(co2)


```


**Part 4 (4 points)**

The file `co2_weekly_mlo.txt` contains weekly observations of atmospheric carbon dioxide concentrations measured at the Mauna Loa Observatory from 1974 to 2020, published by the National Oceanic and Atmospheric Administration (NOAA). Convert these data into a suitable time series object, conduct a thorough EDA on the data, and address the problem of missing observations. Describe how the Keeling Curve evolved from 1997 to the present and compare current atmospheric CO2 levels to those predicted by your forecasts in Parts 2 and 3. Use the weekly data to generate a month-average series from 1997 to the present, and compare the overall forecasting performance of your models from Parts 2 and 3 over the entire period.  

**Part 5 (3 points)**

Seasonally adjust the weekly NOAA data, and split both seasonally-adjusted (SA) and non-seasonally-adjusted (NSA) series into training and test sets, using the last two years of observations as the test sets. For both SA and NSA series, fit ARIMA models using all appropriate steps. Measure and discuss how your models perform in-sample and (psuedo-) out-of-sample, comparing candidate models and explaining your choice. In addition, fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to that of your ARIMA model.

```{r}
co2.noaa.weekly.ts

```

**Part 6 (3 points)**

Generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric C02 levels in the year 2100. How confident are you that these are accurate predictions?










